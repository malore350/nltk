{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This code returns only the main body of the text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-13T13:24:06.132163700Z",
     "start_time": "2023-05-13T13:24:06.095112Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//github.com/Han8931/rsmi_nlp .\n",
      "1 Introduction\n",
      "In response to the threat of textual adversarial at-\n",
      "tacks (Ebrahimi et al., 2018; Jin et al., 2020), a vari-\n",
      "ety of defense schemes have been proposed (Goyal\n",
      "et al., 2022; Ye et al., 2020; Zhou et al., 2021; Dong\n",
      "et al., 2021). Defense schemes typically involve\n",
      "solving a min-max optimization problem, consist-\n",
      "ing of an inner maximization that seeks the worst\n",
      "(adversarial) example and an outer minimization\n",
      "that aims to minimize a system’s loss over such\n",
      "examples (Madry et al., 2018). The solution to\n",
      "the inner maximization problem is typically ob-\n",
      "tained through iterative optimization algorithms,\n",
      "such as stochastic gradient descent (Ilyas et al.,\n",
      "2019; Madry et al., 2018).\n",
      "Class-2 AdvEx Class-1 \n",
      "(a) Randomized Smoothing\n",
      "This is an OK adaptation  of the breath taking book....\n",
      "This is an OK changing  of the breath taking book....\n",
      "This is an OK [MASK]  of the breath taking book...\n",
      "Context Info Context InfoDe-noising\n",
      "(b) Gradient-Guided Masking Positive Sentiment\n",
      "Negative SentimentFigure 1: An overview of RSMI. (a) Random-\n",
      "ized smoothing (RS) provides a certiﬁable robustness\n",
      "within a ball with a radius Raround an input point\n",
      "x(c.f.,Rcan be computed by Theorem 1) and (b)\n",
      "masked inference (MI) denoises “adversarially salient”\n",
      "tokens via a gradient-based feature attribution analysis\n",
      "to make a decision on the input sample with the sur-\n",
      "rounding contexts of a masked token in the input.\n",
      "For texts, however, the gradients cannot be di-\n",
      "rectly computed due to the discrete nature of the\n",
      "texts. Thus, the gradients are often computed with\n",
      "respect to word embeddings of an input sequence\n",
      "as done in Miyato et al. (2016); Zhu et al. (2020);\n",
      "Wang et al. (2021a). The simplicity of the gradient-\n",
      "based adversarial training makes it attractive de-\n",
      "fense strategy, but it tends to show substantial vari-\n",
      "ance in robustness enhancement ( c.f.,§4.7). An-\n",
      "other prevailing approach in natural language pro-\n",
      "cessing (NLP) ﬁeld is to substitute input words of\n",
      "their synonyms sampled from a pre-deﬁned syn-\n",
      "onym set (Ye et al., 2020; Zhou et al., 2021; Dong\n",
      "et al., 2021). The synonym-based defense (SDA)arXiv:2305.06522v1  [cs.CL]  11 May 2023algorithms have emerged as a prominent defense\n",
      "approach since many textual attack algorithms per-\n",
      "turb input texts at a word level (Ren et al., 2019;\n",
      "Alzantot et al., 2018; Jin et al., 2020). However, Li\n",
      "et al. (2021) pointed out that they tend to show sig-\n",
      "niﬁcant brittleness when they have no access to the\n",
      "perturbation sets of the potential attacks. In addi-\n",
      "tion, assuming access to the potential perturbation\n",
      "sets is often unrealistic.\n",
      "To address the issues, we propose RSMI, a\n",
      "novel two-stage framework leveraging randomized\n",
      "smoothing (RS) and masked inference (MI) ( c.f.,\n",
      "Fig. 1). Randomized smoothing is a generic class of\n",
      "methods that transform a classiﬁer into a smoothed\n",
      "classiﬁer via a randomized input perturbation pro-\n",
      "cess (Cohen et al., 2019; Lécuyer et al., 2019). It\n",
      "has come recently into the spotlight thanks to its\n",
      "simplicity and theoretical guarantee of certiﬁable\n",
      "robustness within a ball around an input point (Co-\n",
      "hen et al., 2019; Salman et al., 2019), which is often\n",
      "considered desirable property of a defense scheme\n",
      "(c.f.,Fig. 1 (a)). Moreover, its robustness enhance-\n",
      "ment is highly scalable to modern large-scale deep\n",
      "learning setups (Cohen et al., 2019; Lécuyer et al.,\n",
      "2019). These properties render it a promising re-\n",
      "search direction. However, there exists a non-trivial\n",
      "challenge in introducing RS to NLP systems due to\n",
      "the discrete nature of texts. We sidestep the issue\n",
      "and adapt RS to NLP problems by injecting noise\n",
      "at the hidden layers of the deep neural model. We\n",
      "show that perturbed representations of pre-trained\n",
      "language models (PLMs) still guarantees the ro-\n",
      "bustness in §2.\n",
      "The RS stage is followed by a gradient-guided\n",
      "masked inference (MI) to further reinforce the\n",
      "smoothing effect of RS. MI draws an inference\n",
      "on an input sequence via a noise reduction pro-\n",
      "cess that masks adversarially “salient” tokens in\n",
      "the input that are potentially perturbed by an attack\n",
      "algorithm ( c.f.,Fig. 1 (b)). The adversarially salient\n",
      "tokens are achieved via a gradient-based feature\n",
      "attribution analysis rather than random selections\n",
      "as commonly done in pre-training language models\n",
      "(Devlin et al., 2019) to effectively suppress adver-\n",
      "sarial perturbations. The effectiveness of our novel\n",
      "MI can be attributed to several aspects: ( i) It is a\n",
      "natural regularization for forcing the model to make\n",
      "a prediction based on the surrounding contexts of\n",
      "a masked token in the input (Moon et al., 2021).\n",
      "(ii) It works without any prior assumption about po-\n",
      "tential attacks, which renders it an attack-agnosticdefense approach and is more practical in that it\n",
      "requires no sub-module for synonym-substitution.\n",
      "(iii) It has a close theoretical connection to the\n",
      "synonym-substitution-based approaches, as MI can\n",
      "be regarded as a special case of the weighted en-\n",
      "semble over multiple transformed inputs as shown\n",
      "in §2.2.\n",
      "We evaluate the performance of RSMI through\n",
      "comprehensive experimental studies on large-scale\n",
      "PLMs with three benchmark datasets against\n",
      "widely adopted adversarial attacks. Our empirical\n",
      "studies demonstrate that RSMI obtains improve-\n",
      "ments of 2to3times against strong adversarial\n",
      "attacks in terms of key robustness metrics over base-\n",
      "line algorithms despite its simplicity (§4.1). We\n",
      "also conduct theoretical analysis to demonstrate\n",
      "the effectiveness of our adapted RS (§2.1) and MI\n",
      "(§2.2 and appendix A.6). We further analyze the\n",
      "scalability of RSMI, the inﬂuence of hyperparam-\n",
      "eters, its impact on the latent representation ( i.e.,\n",
      "embedding space) of the system and its stochas-\n",
      "tic stability (§4.5). Our theoretical and empirical\n",
      "analyses validate the effectiveness of RSMI and\n",
      "propose it as a practical method for training adver-\n",
      "sarially robust NLP systems.\n",
      "2 Randomized Smoothing with Masked\n",
      "Inference (RSMI)\n",
      "We consider a standard text classiﬁcation task with\n",
      "a probabilistic model F\u0012:Rd!P (Y), where\n",
      "P(Y)is the set of possible probability distributions\n",
      "over class labelsY=f1;:::;Cg, and \u00122Rp\n",
      "denotes the parameters of the model F\u0012(orF\n",
      "for simplicity). The model Fis trained to ﬁt a\n",
      "data distributionDover pairs of an input sequence\n",
      "s= (s1;:::;sT)ofTtokens and its correspond-\n",
      "ing class label y2Y. The distributed represen-\n",
      "tation ofs(or word embedding) is represented\n",
      "asx= [x1;:::;xT]. We assume the model is\n",
      "trained with a loss function Lsuch as cross-entropy.\n",
      "We denote the ﬁnal prediction of the model as\n",
      "^y= arg maxiF(s)iand the ground truth label\n",
      "asy\u0003.\n",
      "2.1 Randomized smoothing via noise layers\n",
      "Given the model F, our method exploits a random-\n",
      "ized smoothing (Lécuyer et al., 2019; Cohen et al.,\n",
      "2019) approach to obtain a smoothed version of it,\n",
      "denoted by G:Rd!P (Y), which is provably\n",
      "robust under isotropic Gaussian noise perturbation\n",
      "\u000Eat an input query u(e.g., an image). This can beexpressed as:\n",
      "Deﬁnition 1 Given an original probabilistic neu-\n",
      "ral network classiﬁer F, the associated smoothed\n",
      "classiﬁerGat a queryucan be denoted as ( a.k.a.\n",
      "Weierstrass Transform (Ahmed I, 1996)):\n",
      "G(u) = (F\u0003N(0;\u001B2I))(u)\n",
      "=E\u000E\u0018N(0;\u001B2I)[F(u+\u000E)]:(1)\n",
      "The standard deviation of the Gaussian noise\n",
      "\u001Bis a hyperparameter that controls the robust-\n",
      "ness/accuracy trade-off of the resulting smoothed\n",
      "modelG. The higher the noise level is, the more\n",
      "robust it will be, while the prediction accuracy\n",
      "may decrease. The asterisk \u0003denotes a convo-\n",
      "lution operation (Oppenheim et al., 1996) which,\n",
      "for any two functions hand , can be deﬁned as:\n",
      "h\u0003 (x) =R\n",
      "Rdh(t) (x\u0000t)dt. In practice, G(u)\n",
      "can be estimated via Monte-Carlo sampling (Cohen\n",
      "et al., 2019; Salman et al., 2019).\n",
      "Cohen et al. (2019) showed that the smoothed\n",
      "modelGis robust around a query point uwithin a\n",
      "L2radiusR, which is given by:\n",
      "R=\u001B\n",
      "2\u00001(pa)\u00001(pb)); (2)\n",
      "where\u00001is the inverse of the standard Gaus-\n",
      "sian CDF, paandpbare the probabilities\n",
      "of the two most likely classes aandb, de-\n",
      "noted as:a= arg maxy2YG(x)yandb=\n",
      "arg maxy2YnaG(x)y.\n",
      "As per Eq. (1), a simple approach to obtain G\n",
      "is to perturb the input uby the noise \u000Eand train\n",
      "with it. However, for a textual input, the token\n",
      "sequence cannot be directly perturbed by \u000Edue to\n",
      "the its discrete nature. To deviate from the issue,\n",
      "we inject noise at the hidden layers of the model to\n",
      "achieve stronger smoothness as done in (Liu et al.,\n",
      "2018). For a given layer fl, a noise layer f\u000E\n",
      "ldraws\n",
      "a noise\u000E\u0018N(0;\u001B2I)and adds it to the output of\n",
      "flin every forward pass of the model. The stronger\n",
      "smoothness resulting from the multi-layer noise is\n",
      "provably guaranteed by the following theorem:\n",
      "Theorem 1 LetF:Rd! P (Y)be any soft\n",
      "classiﬁer which can be decomposed as F=\n",
      "f1\u000Ef2\u000E\u0001\u0001\u0001\u000EfLandG=g1\u000Eg2\u000E\u0001\u0001\u0001\u000E\n",
      "gLbe its associated smoothed classiﬁer, where\n",
      "gl(x) = (fl\u0003N(0;\u001B2\n",
      "lI))(x)with 1\u0014l\u0014L\n",
      "and\u001Bl>0. Leta= arg maxy2YG(x)yand\n",
      "b= arg maxy2YnaG(x)ybe two most likely\n",
      "classes forxaccording to G. Then, we have that\n",
      "arg maxy2YG(x0)y=aforx0satisfying\n",
      "x0\u0000x\r\n",
      "2\u00141\n",
      "2\u001B1LY\n",
      "l=2(1 +\u001B2\n",
      "l)\u00001(pa)\u00001(pb)):We provide a proof of the theorem with Lipschitz\n",
      "continuity in Appendix F.\n",
      "2.2 Gradient-guided masked inference\n",
      "For an input sequence s, our method attempts to\n",
      "denoise its adversarially perturbed counterpart s0\n",
      "by attributing saliency of input tokens through a\n",
      "simple gradient-based attribution analysis. Due to\n",
      "the discrete nature of tokens, we compute the gradi-\n",
      "ents of the loss function Lwith respect to the word\n",
      "embeddings xt. The loss is computed with respect\n",
      "to the labels y, which is set to be the ground-truth\n",
      "labelsy\u0003during training and model predictions ^y\n",
      "during inference. Formally, the gradients gtfor\n",
      "a tokenst2s(correspondingly xt2x) can be\n",
      "computed as follows:\n",
      "gt=rxtL(G(x);y)\n",
      "\u0019\u0000rxt\u0012\n",
      "log\u00121\n",
      "\u0017\u0017X\n",
      "i=1G(x+\u000Ei)\u0013\u0013\n",
      ":(3)\n",
      "Eq. (3) exploits a Monte-Carlo approximation to\n",
      "estimate the gradient gtas done in (Salman et al.,\n",
      "2019). Subsequently, the amount of stimulus of the\n",
      "input tokens toward the model prediction is mea-\n",
      "sured by computing the L2-norm of gt,i.e.,jjgtjj2.\n",
      "The stimulus is regarded as the saliency score of the\n",
      "tokens and they are sorted in descending order of\n",
      "the magnitude (Li et al., 2016; Moon et al., 2022).\n",
      "Then, we sample Mtokens from the top- Ntokens\n",
      "ins, and mask them to generate a masked input\n",
      "sequencem= [s1;:::;mt;:::;sT], wheretis the\n",
      "position of a salient token and mtis the mask to-\n",
      "ken,[MASK ]. During training, we mask the top- M\n",
      "positions ( i.e.,N=M), while the mask token se-\n",
      "lection procedure is switched to a sampling-based\n",
      "approach during inference as detailed later in §2.3.\n",
      "Finally, the gradients gtcomputed for generating\n",
      "the masked sequence is repurposed for perturbing\n",
      "the word embeddings xt(i.e.,\u000E=gt) to obtain\n",
      "robust embeddings as shown in (Zhu et al., 2020;\n",
      "Wang et al., 2021a; Miyato et al., 2017).\n",
      "Our gradient-guided masked inference offers\n",
      "several advantages. First, it yields a natural regular-\n",
      "ization for forcing the model to exploit surrounding\n",
      "contexts of a masked token in the input (Moon et al.,\n",
      "2021). Second, the masking process can provide a\n",
      "better smoothing effect by masking ‘salient’ tokens\n",
      "that are probably adversarial to the model’s deci-\n",
      "sion. In such cases, it works as a denoising process\n",
      "for reducing the strength of an attacks. In Ap-\n",
      "pendix A.6, we conduct theoretical analysis aboutthe denoising effect of the gradient-guided masked\n",
      "inference in terms of Lipschitz continuity of a soft\n",
      "classiﬁer.\n",
      "Connection to synonym-based defense meth-\n",
      "ods Another interesting interpretation is that the\n",
      "masked inference has a close connection to the\n",
      "synonym-based defense methods (Wang et al.,\n",
      "2021b; Ye et al., 2020; Wang and Wang, 2020;\n",
      "Zhou et al., 2021). Assuming only position in sis\n",
      "masked and treating the mask as a latent variable\n",
      "~stthat could take any token from the vocabulary\n",
      "V, we can express the masked inference as:\n",
      "p(yjm) =X\n",
      "~st2Vp(y;~stjm) (4)\n",
      "=X\n",
      "~st2Vp(yjm;~st)p(~stjm) (5)\n",
      "\u0019X\n",
      "~st2Vtp(yjm;~st)p(~stjm); (6)\n",
      "wherejVtj\u001CjVjis the number of words to be at\n",
      "positiontwith a high probability mass. As shown\n",
      "in the equation, the masked inference can be fac-\n",
      "torized into a classiﬁcation objective and a masked\n",
      "language modeling objective, which can be further\n",
      "approximated into a weighted ensemble inference\n",
      "withjVtjsubstitutions of swith the highly proba-\n",
      "ble tokens ( e.g., synonyms) corresponding to the\n",
      "original word st. If we assume p(~stjm)to be a\n",
      "probability of sampling uniformly from a synonym\n",
      "set such as the one from the WordNet (Fellbaum,\n",
      "1998), then the masked inference is reduced to a\n",
      "synonym-substitution based defense approach with\n",
      "no necessity of an explicit synonym set.\n",
      "2.3 Two-step Monte-Carlo sampling for\n",
      "efﬁcient inference\n",
      "The prediction procedure of RSMI involves av-\n",
      "eraging predictions of kMonte-Carlo samples of\n",
      "G(m)to deal with the variations in the noise lay-\n",
      "ers. A large number of kis typically required for\n",
      "a robust prediction but the computational cost in-\n",
      "creases proportionally as kgets larger. To allevi-\n",
      "ate the computational cost, we propose a two-step\n",
      "sampling-based inference (Alg. 1).\n",
      "In the ﬁrst step, we make k0predictions by es-\n",
      "timatingG(m)fork0times (k0forward passes).\n",
      "We then make an initial guess about the label of\n",
      "the masked sample mby taking a majority vote\n",
      "of the predictions. Following Cohen et al. (2019),\n",
      "this initial guess is then tested by a one-tailed bi-\n",
      "nomial test with a signiﬁcance level of \u000B. If theguess passes the test, we return the most probable\n",
      "class based on the vote result. If it fails, then we\n",
      "attempt to make a second guess with a set of k1\n",
      "masked input sequences M= [m(1);\u0001\u0001\u0001;m(k1)],\n",
      "wherek0\u001Ck1. Note that the masked input m\n",
      "used in the ﬁrst step is generated by masking the\n",
      "top-Mtokens from the top- Ncandidates as we do\n",
      "during training. However, in the second step, we\n",
      "randomly sample Mmasking positions from the\n",
      "Ncandidates to create each masked sequence m(i)\n",
      "ofMin order to maximize variations in the predic-\n",
      "tions; this step is denoted as RANDGRADMASK in\n",
      "Alg. 1.\n",
      "Our two-step sampling based inference is based\n",
      "on an assumption that textual adversarial exam-\n",
      "ples are liable to fail to achieve consensus from\n",
      "the RSMI’s predictions compared to clean sam-\n",
      "ples. In other words, it is considerably harder for\n",
      "adversarial examples to estimate the optimal pertur-\n",
      "bation direction towards the decision boundary of\n",
      "a stochastic network (Däubener and Fischer, 2022;\n",
      "Athalye et al., 2018; Cohen et al., 2019). We con-\n",
      "duct experiments to show the effectiveness of our\n",
      "two-step sampling based inference in §4.5.\n",
      "3 Experiment Setup\n",
      "Datasets We evaluate RSMI on two conventional\n",
      "NLP tasks: text CLaSsiﬁcation (CLS) and Natural\n",
      "Language Inference (NLI). We adopt IMD B(Maas\n",
      "et al., 2011) and AG’ SNEWS (Zhang et al., 2015)\n",
      "datasets for the classiﬁcation task. For NLI, we\n",
      "compare the defense algorithms on the Question-\n",
      "answering NLI (QNLI) dataset, which is a part of\n",
      "the GLUE benchmark (Wang et al., 2018). We\n",
      "build development sets for IMD B,AG, and QNLI\n",
      "by randomly drawing 10% samples from each train-\n",
      "ing set via a stratiﬁed sampling strategy.\n",
      "Evaluation metrics The performance of defense\n",
      "algorithms is evaluated in terms of four different\n",
      "metrics as proposed in (Li et al., 2021): ( i) Stan-\n",
      "dard accuracy (SAcc) is the model’s accuracy on\n",
      "clean samples. ( ii) Robust accuracy (RAcc) mea-\n",
      "sures the model’s robustness against adversarial at-\n",
      "tacks. ( iii) Attack success rate (ASR) is the ratio of\n",
      "the inputs that successfully fool the victim models.\n",
      "(iv) Finally, the average number of queries (AvgQ)\n",
      "needed to generate the adversarial examples.Algorithm 1 Training and prediction procedure of RSMI.\n",
      "1:Initialize.s,M,N,\u001B,\u0017,k0,k1,\u000B, step size\u0011, and a gradient scale parameter \f.\n",
      "2:ComputeL:=\u0002\n",
      "jjg1jj2;\u0001\u0001\u0001;jjgTjj2\u0003\n",
      "via Eq. (3). .Gradients w.r.t. word embeddings\n",
      "3:SortLin descending order and keep top- Nitems\n",
      "4:Get a masked sequence mby masking top- Mtokens based on L.\n",
      "5:ifTraining then\n",
      "6:x:=x+\f(g1;\u0001\u0001\u0001;gT) .Noise to word embeddings\n",
      "7: \u0012:=\u0012\u0000\u0011r\u0012L(G(x);y\u0003)\n",
      "8:else if Prediction then\n",
      "9: \u001E(m)0=Pk0\n",
      "i=1[I(^y(i)(m) =y1);\u0001\u0001\u0001;I(^y(i)(m) =yc)] .First vote\n",
      "10:na= max \u001E(m)0\n",
      "11:p-value = B INOM TEST(na;k0;0:5,one-tail)\n",
      "12: ifp-value>\u000B then\n",
      "13: Return arg maxy2Y\u001E(m)0\n",
      "14: else\n",
      "15: [m(1);\u0001\u0001\u0001;m(k1)]\u0018RAND GRADMASK(k1;L)\n",
      "16: \u001E(m)1=Pk1\n",
      "i=1[I(^y(m(i)) =y1);\u0001\u0001\u0001;I(^y(m(i)) =yc)] .Second vote\n",
      "17: Return arg maxy2Y\u001E(m)1\n",
      "18: end if\n",
      "19:end if\n",
      "Baselines We select FreeLB (Zhu et al., 2020)1,\n",
      "InfoBERT (Wang et al., 2021a), and an adversarial\n",
      "example augmentation (AdvAug) (Li et al., 2021)\n",
      "as baselines since they are representative work\n",
      "for gradient-based training, information-theoretical\n",
      "constraint, data augmentation approaches, respec-\n",
      "tively. We also choose SAFER (Ye et al., 2020)\n",
      "since it is a certiﬁable defense method based on\n",
      "a synonym-substitution-based approach. We then\n",
      "apply the baselines over BERT-base (Devlin et al.,\n",
      "2019) and RoBERTa-base (Liu et al., 2019) mod-\n",
      "els. We also conduct experiments with RoBERTa-\n",
      "Large, BERT-Large, and T5-Large (Raffel et al.,\n",
      "2022) models to observe scalability of RSMI. Note\n",
      "that our experiment setup is signiﬁcantly larger\n",
      "compared to previous works, including Li et al.\n",
      "(2021); Ye et al. (2020). The baseline algorithms\n",
      "are tuned according to their default conﬁgurations\n",
      "presented in the respective papers and run them\n",
      "three times with a different random initialization to\n",
      "obtain the best performance of the baselines. For\n",
      "AdvAug, we augment a training dataset of each\n",
      "task by adversarial examples sampled from 10k\n",
      "data points of training datasets. Further details are\n",
      "provided in Appendix E.\n",
      "Textual adversarial attacks We generate ad-\n",
      "versarial examples via TextFooler (TF) (Jin\n",
      "1FreeLB++ (Li et al., 2021) is excluded since it has a\n",
      "reproducibility issue as reported in github.et al., 2020), Probability Weighted Word Saliency\n",
      "(PWWS) (Ren et al., 2019) and BERT-based Adver-\n",
      "sarial Examples (BAE) (Garg and Ramakrishnan,\n",
      "2020). These attack algorithms are widely adopted\n",
      "in a variety of defense works as adversarial ro-\n",
      "bustness benchmarking algorithms (Yoo and Qi,\n",
      "2021; Dong et al., 2021) since they tend to gener-\n",
      "ate adversarial examples with better retention of\n",
      "semantics and show high attack effectiveness com-\n",
      "pared to syntactic paraphrasing attacks (Iyyer et al.,\n",
      "2018). Moreover, the above attack algorithms have\n",
      "their own distinct attack process. For instance, TF\n",
      "and PWWS build synonym sets by counter-ﬁtting\n",
      "word embeddings (Mrkši ´c et al., 2016) and Word-\n",
      "Net (Fellbaum, 1998), respectively. BAE leverages\n",
      "BERT for building a synonym set of a target token.\n",
      "Note that we exclude some adversarial attack algo-\n",
      "rithms, such as BERT-Attack (Li et al., 2020) due\n",
      "to their expensive computation costs2.\n",
      "We randomly draw 1,000 samples from each test\n",
      "set following Dong et al. (2021); Li et al. (2021);\n",
      "Ye et al. (2020) for a fair comparison and perturb\n",
      "them via an attack to generate the corresponding ad-\n",
      "versarial examples for all experiments unless stated\n",
      "otherwise. The sample size is also partially due to\n",
      "the slow attack speed of textual adversarial attack\n",
      "2BERT-Attack takes around 2k times more than TextFooler\n",
      "algorithm to generate a single adversarial example of a AG-\n",
      "News sample under our experiment setup. This issue is also\n",
      "reported in TextAttack (Morris et al., 2020).Dataset PLM Model SAcc ( \") RAcc (\") ASR ( #) AvgQ ( \")\n",
      "TF PWWS BAE Avg. TF PWWS BAE Avg. TF PWWS BAE Avg.\n",
      "IMDbBERT-base+ Fine-Tuned 90.60 5.90 0.60 27.30 11.27 93.49 99.34 69.87 87.57 440 1227 377 681\n",
      "+ FreeLB (Zhu et al., 2020) 92.90 10.50 14.22 45.30 23.34 88.70 84.71 51.24 74.88 909 1400 442 917\n",
      "+ InfoBERT (Wang et al., 2021a) 92.90 26.40 26.80 50.00 34.40 71.58 71.15 46.18 62.97 1079 1477 458 1005\n",
      "+ SAFER (Ye et al., 2020) 91.80 23.80 30.90 38.20 30.97 74.08 66.34 58.39 66.27 1090 1504 618 1071\n",
      "+ AdvAug 92.60 32.00 36.60 52.10 40.23 65.44 60.48 43.74 56.55 1291 1569 478 1113\n",
      "+ RSMI-NoMask (Our) 91.00 34.90 57.00 58.40 50.10 61.65 37.36 35.83 44.95 1395 1733 817 1315\n",
      "+ RSMI (Our) 92.20 56.40 58.70 80.20 65.10 38.83 36.34 13.02 29.40 1651 1764 1287 1567\n",
      "RoBERTa-base+ Fine-Tuned 93.10 0.50 1.10 22.60 8.07 99.46 98.82 75.73 91.34 588 1248 398 745\n",
      "+ FreeLB (Zhu et al., 2020) 93.20 17.30 21.20 49.50 29.33 81.44 77.25 46.89 68.53 999 1433 461 964\n",
      "+ InfoBERT (Wang et al., 2021a) 94.00 7.60 13.20 36.10 18.97 91.92 85.96 61.60 79.83 855 1388 418 887\n",
      "+ SAFER (Ye et al., 2020) 93.20 31.80 39.20 45.40 38.80 65.88 57.94 51.29 58.37 1276 1575 678 1176\n",
      "+ AdvAug 94.40 28.90 31.60 51.40 37.30 69.39 66.53 45.55 60.49 1220 1567 479 1089\n",
      "+ RSMI-NoMask (Our) 93.30 47.00 54.00 52.10 51.03 49.63 42.12 44.16 45.30 1455 1684 764 1301\n",
      "+ RSMI (Our) 93.00 73.40 76.20 83.00 77.53 21.08 18.07 10.75 16.63 1917 1863 1314 1698\n",
      "AGNewsBERT-base+ Fine-Tuned 93.90 16.80 34.00 81.00 43.93 82.11 63.79 13.74 53.21 330 352 124 269\n",
      "+ FreeLB (Zhu et al., 2020) 95.00 24.40 48.20 84.10 52.23 74.32 49.26 11.47 45.02 383 367 131 294\n",
      "+ InfoBERT (Wang et al., 2021a) 94.81 19.90 40.90 84.90 48.57 79.01 56.86 10.45 48.77 371 365 126 287\n",
      "+ SAFER (Ye et al., 2020) 93.70 46.30 64.00 80.00 63.43 50.59 31.70 14.62 32.30 447 379 170 332\n",
      "+ AdvAug 93.90 54.90 66.00 80.10 67.00 41.53 29.71 14.70 28.65 465 386 129 327\n",
      "+ RSMI-NoMask (Our) 92.60 60.40 75.30 77.90 71.20 34.77 18.68 15.88 23.11 497 395 203 365\n",
      "+ RSMI (Our) 92.70 63.20 76.10 86.10 75.13 31.82 17.91 7.12 18.95 503 397 573 491\n",
      "RoBERTa-base+ Fine-Tuned 93.91 23.90 49.30 80.00 51.07 74.55 47.50 14.80 45.62 353 367 130 283\n",
      "+ FreeLB (Zhu et al., 2020) 95.11 23.90 48.20 83.00 51.70 74.87 49.32 12.73 45.64 393 374 127 298\n",
      "+ InfoBERT (Wang et al., 2021a) 94.00 30.20 52.30 79.80 54.10 67.87 44.36 15.11 42.45 396 374 134 301\n",
      "+ SAFER (Ye et al., 2020) 93.60 49.30 68.90 81.60 66.60 47.33 26.39 12.82 28.85 452 386 172 337\n",
      "+ AdvAug 94.00 61.00 70.90 81.30 71.07 35.11 24.57 13.51 24.40 486 388 133 336\n",
      "+ RSMI-NoMask (Our) 94.10 66.40 79.00 82.80 76.07 29.44 16.05 12.01 19.17 504 396 213 371\n",
      "+ RSMI (Our) 94.30 74.10 81.90 88.60 81.53 21.42 13.15 6.04 13.54 530 401 576 502\n",
      "Table 1: Performance comparison of adversarial robustness of RSMI with the baselines for classiﬁcation tasks.\n",
      "RSMI-NoMask excludes masking during inference time. Avg. stands for an average of evaluation results.\n",
      "algorithms and the strong robustness of the pro-\n",
      "posed model, which requires the attack algorithms\n",
      "to query a huge amount of times compared to the\n",
      "baselines ( c.f.,Table 1). We implement all attacks\n",
      "through the publicly available TextAttack library\n",
      "(Morris et al., 2020) and use their default conﬁgu-\n",
      "rations without any explicit attack constraints.\n",
      "For robustness evaluation of RSMI against the\n",
      "attacks, we modify the second step of the two-step\n",
      "inference to make a ﬁnal decision by averaging\n",
      "logit scores of k1Monte-Carlo samples instead\n",
      "of the majority voting approach in Alg. 1. We\n",
      "do this to prevent obfuscating the perturbation pro-\n",
      "cesses of TF and PWWS that are devised to identify\n",
      "target tokens via the change of the model’s conﬁ-\n",
      "dence, which can give a false impression about the\n",
      "robustness of RSMI. Nonetheless, we investigate\n",
      "the effectiveness of majority voting based infer-\n",
      "ence as a practical defense method in Appendix B.\n",
      "Further details about the attack algorithms and pa-\n",
      "rameter settings of the algorithms are provided in\n",
      "Appendix E.\n",
      "4 Results and Analysis\n",
      "4.1 Adversarial robustness comparison\n",
      "We compare the performance of RSMI with the\n",
      "baselines in Table 1. Overall, we observe that\n",
      "RSMI outperforms all the baselines by quite a largemargin across the majority of the metrics such as\n",
      "RAcc, ASR and AvgQ. In particular, it achieves\n",
      "about 2 to 3 times improvements against strong\n",
      "attack algorithms ( e.g., TextFooler and PWWS) in\n",
      "terms of ASR and RAcc, which are key metrics\n",
      "for evaluating the robustness of defense algorithms.\n",
      "RSMI also signiﬁcantly outperforms the baselines\n",
      "in QNLI task by 16%\u001826% (c.f.,Appendix C). In\n",
      "addition, we observe that RSMI tends to show bet-\n",
      "ter training stability in RAcc compared to the base-\n",
      "lines ( c.f.,§4.7). For instance, the RAcc of FreeLB\n",
      "shows a standard deviation of 8.57%, but RSMI\n",
      "shows 2.10% for the IMDb task. Also, InfoBERT\n",
      "tuned for AGNews shows a standard deviation of\n",
      "13.19% in RAcc while RSMI shows 0.84%. We\n",
      "also emphasize that RSMI outperforms other exist-\n",
      "ing methods, such as TA V AT (Li and Qiu, 2020),\n",
      "MixADA (Si et al., 2020), A2T (Yoo and Qi, 2021),\n",
      "and ASCC (Dong et al., 2021) which we do not\n",
      "report in Table 1 as they show lower performance\n",
      "than our baselines, c.f.,Li et al. (2021).3Another\n",
      "interesting observation is that a simple AdvAug\n",
      "approach outperforms sophisticated methods, in-\n",
      "cluding InfoBERT, FreeLB, and SAFER in most\n",
      "experiment setups without hurting SAcc. This runs\n",
      "contrary to the claims in Li et al. (2021); Si et al.\n",
      "3Li et al. (2021) put constraints to make the attack algo-\n",
      "rithms weaker which we did not do in our work.Dataset Model SAcc ( \") RAcc (\") ASR (#) AvgQ (\")\n",
      "IMDbBERT-Large + RSMI 93.16(+0.66) 79.30(+49.80) 14.88(-53.23) 1980(+850)\n",
      "RoBERTa-Large + RSMI 95.06(+0.76) 87.40(+66.20) 8.06 (-69.46) 2092(+1058)\n",
      "T5-Large + RSMI 94.41(+0.38) 62.87(+35.24) 33.40(-37.21) 1684(+598)\n",
      "AGNewsBERT-Large + RSMI 94.60(-0.70) 85.70(+65.10) 9.41 (-68.97) 568 (+210)\n",
      "RoBERTa-Large + RSMI 94.60(+0.54) 88.10(+46.60) 6.87 (-49.01) 577 (+144)\n",
      "T5-Large + RSMI 94.90(-0.10) 75.10(+13.56) 20.86(-14.37) 516(+89)\n",
      "Table 2: Performance of adversarial robustness of RSMI on large-scale PLMs. The round brackets next to each\n",
      "number denote the change of score compared to its ﬁne-tuned model.\n",
      "(2020).\n",
      "The strong performance of RSMI can be at-\n",
      "tributed to four factors: ( i) A provable robustness\n",
      "guarantee by the randomized smoothing approach\n",
      "helps attain higher robustness ( c.f.,Theorem 1).\n",
      "To further support this claim, we evaluate the ro-\n",
      "bustness of RSMI without the proposed masking\n",
      "process ( i.e.,MI) during inference and the results\n",
      "are reported as RSMI-NoMask in Table 1. As we\n",
      "can see, RSMI-NoMask outperforms the baselines\n",
      "in most experiment scenarios. ( ii) The random-\n",
      "ized smoothing denoises adversarial perturbations\n",
      "in the latent space of systems. Our experiments in\n",
      "§4.3 bolster this claim by showing the signiﬁcant\n",
      "noise reduction in hidden representations of RSMI.\n",
      "(iii) The MI leads to a reduction in the noise of\n",
      "the adversarial perturbations. This claim can be\n",
      "strongly bolstered again by comparing the results\n",
      "of RSMI with and without the masking strategy\n",
      "during inference ( c.f.,RSMI-NoMask and RSMI\n",
      "in Table 1). ( iv) The two-step sampling-based in-\n",
      "ference makes it harder for the attack algorithms\n",
      "to estimate the optimal perturbation direction to\n",
      "fool the model for an input sample. An ablation\n",
      "study in §4.5 clearly supports this claim since the\n",
      "two-step sampling signiﬁcantly improves the RAcc\n",
      "of RSMI models.\n",
      "4.2 Large scale parameterization and\n",
      "adversarial robustness\n",
      "We investigate the scalability of RSMI by applying\n",
      "RSMI over large-scale PLMs, such as RoBERTa-\n",
      "Large and BERT-Large, both of which have 340\n",
      "million parameters. We also conduct experiments\n",
      "with T5-Large model of 770 million parameters.\n",
      "Then, we evaluate their robustness via TextFooler\n",
      "attack algorithm since it tends to show high ASR\n",
      "(c.f.,Table 1). Table 2 summarizes the experiment\n",
      "results. From Table 2, we can clearly observe that\n",
      "RSMI signiﬁcantly improves the robustness of the\n",
      "RoBERTa-FT\n",
      "RoBERTa-RSMI BERT-RSMIBERT-FT\n",
      "0 5 1025\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      " 0\n",
      "0 5 101.0\n",
      "0.8\n",
      "0.6\n",
      "0.4\n",
      " 0.2(a)(b)Figure 2: Analysis of hidden representations of RSMI.\n",
      "We compare the L2distance and cosine similarity be-\n",
      "tween a hidden representation of clean sample and that\n",
      "of its corresponding adversarial example.\n",
      "large PLMs, which indicates the high scalability\n",
      "of RSMI. Especially, RoBERTa-Large with RSMI\n",
      "enhances the RAcc of the ﬁne-tuned RoBERTa-\n",
      "Large by 66.20% for the IMDb task.\n",
      "4.3 Analysis of latent representations of\n",
      "RSMI\n",
      "We investigate the latent representation of clean\n",
      "samplehl(s)and that of its corresponding adver-\n",
      "sarial example hl(s0)for each layer l. We exam-\n",
      "ine the ﬁne-tuned base models and the base mod-\n",
      "els with RSMI. For each model, we compare the\n",
      "L2distance and cosine similarity between hl(s)\n",
      "andhl(s0)for each layer l. Fig. 2 shows that the\n",
      "L2distance and cosine similarity of the ﬁne-tuned\n",
      "RoBERTa and BERT models stay quite constant\n",
      "until 8-th layer. However, for subsequent layers, L2\n",
      "distance curves rapidly increase and cosine similar-\n",
      "ity curves suddenly fall. At the ﬁnal layer ( l= 12 ),\n",
      "we can observe the largest changes. Thus, the latent\n",
      "representation of the clean sample and its corre-\n",
      "sponding adversarial example become distinct. In\n",
      "contrast, RSMI tends to show signiﬁcant decreasesModel ASR( #)\n",
      "k= 1k= 5k= 10k= 50\n",
      "M= 1RM 86.65 97.95 99.68 100\n",
      "GM 96.55\n",
      "M= 2RM 76.57 90.84 93.11 96.27\n",
      "GM 83.12\n",
      "M= 3RM 70.05 86.34 90.08 92.76\n",
      "GM 90.81\n",
      "M= 4RM 65.34 78.86 79.74 82.64\n",
      "GM 81.34\n",
      "M= 5RM 68.35 86.31 90.70 96.26\n",
      "GM 80.72\n",
      "Table 3: ASR of random masking (RM) and gradient-\n",
      "guided masking (GM) for combinations of Mmasked\n",
      "tokens andkmasked sequences.\n",
      "ofL2distance atl1;l5;andl9thanks to the Gaus-\n",
      "sian noise perturbation processes for these layers.\n",
      "This indicates that RSMI effectively reduces the\n",
      "adversarial noise in the latent representations of\n",
      "adversarial examples.\n",
      "4.4 Effectiveness of gradient-guided masking\n",
      "We probe the effectiveness of the gradient-guided\n",
      "masking strategy by ablating the noise layers\n",
      "and the two-step sampling of RSMI. The result-\n",
      "ing model, namely the gradient-guided masking\n",
      "(GM) is compared to a model trained on randomly\n",
      "masked inputs, namely the random masking model\n",
      "(RM). Note that GM predicts and masks inputs in a\n",
      "deterministic way due to the absence of noise lay-\n",
      "ers. Table 3 summarizes our study of ASR changes\n",
      "of GM and RM over different number of mask to-\n",
      "kensMin an input sequence as well as krandomly\n",
      "masked sequences drawn for estimating an expecta-\n",
      "tion of RM prediction. RM tends to achieve its best\n",
      "performance at k= 1, but shows vulnerability as\n",
      "kincreases, which means its robustness is largely\n",
      "from attack obfuscation rather than improving the\n",
      "model’s robustness (Athalye et al., 2018). On the\n",
      "other hand, ASR of GM tends to decrease as we\n",
      "increaseM. This validates the effectiveness of\n",
      "gradient-guided masking for denoising adversarial\n",
      "perturbations injected by attack algorithms.\n",
      "4.5 Effectiveness of two-step sampling\n",
      "We study the effectiveness of the proposed two-step\n",
      "sampling (TS). Fig. 3 clearly shows that RSMI with\n",
      "TS signiﬁcantly increases the robustness for both\n",
      "BERT and RoBERTa. For instance, RSMI without\n",
      "RAcc(%)\n",
      "Number of transformed inputsRSMI-RoBERTa\n",
      "RSMI-BERT\n",
      "RSMI-RoBERTa w/o TS\n",
      "RSMI-BERT w/o TS\n",
      "75\n",
      "70\n",
      "65\n",
      "60\n",
      "55\n",
      "50\n",
      "1 2 3 4 5Figure 3: RAcc curves of RSMI with two-step (TS)\n",
      "sampling and without TS over input transformations.\n",
      "\u001B M N lASR(#) SAcc(\")\n",
      "0.2 2 3 35.26 93.15\n",
      "0.2 2 4 32.73 93.26\n",
      "0.2 2 5 29.90 93.11\n",
      "0.2 2 3 35.26 93.15\n",
      "0.3 2 3 26.05 92.96\n",
      "0.4 2 3 24.17 92.70\n",
      "0.4 2 3 24.17 92.70\n",
      "0.4 3 3 22.39 92.49\n",
      "0.4 4 3 20.99 92.13\n",
      "Table 4: Study on noise size ( \u001B), number of masks ( M),\n",
      "and number of noise layers ( Nl).\n",
      "TS shows RAcc of 64% at k= 5, but RSMI with\n",
      "TS shows RAcc of 74.1% against TextFooler attack.\n",
      "We credit this robustness to the transform process\n",
      "of RSMI, which masks inputs and perturbs their\n",
      "hidden representation with Gaussian noise. This\n",
      "behaves as a mixture of two stochastic transforma-\n",
      "tions and makes it harder for the attack algorithms\n",
      "to estimate the optimal perturbation direction.\n",
      "4.6 Impact of parameter settings\n",
      "Table 4 shows the impact of different hyperparam-\n",
      "eters of RSMI. As observed, the overall ASR tends\n",
      "to decrease as we inject more noises into models\n",
      "by increasing noise size ( \u001B), replacing more input\n",
      "words with the mask token ( M), and adding more\n",
      "noise layers ( Nl). Speciﬁcally, we observe that\n",
      "ASR gradually decreases as we put more noise lay-\n",
      "ers in the model. Also, ASR steadily declines as\n",
      "we increase the standard deviation of noise. Finally,\n",
      "we observe that the increased number of masks ef-\n",
      "fectively decreases ASR. However, we observe that\n",
      "these improvements in ASR come at the cost of aModel Statistics Avg\u0006STD Max Min\n",
      "RoBERTa-base\n",
      "+FreeLB SAcc- Dtest93:82\u00060:6794.24 93.05\n",
      "RAcc 9:21\u00068:5717.30 0.23\n",
      "+InfoBERT SAcc- Dtest94:14\u00060:1094.24 94.05\n",
      "RAcc 5:20\u00062:247.60 3.17\n",
      "+RSMI SAcc- Dtest92:11\u00060:3092.40 91.80\n",
      "RAcc 71:00\u00062:1073.40 69.50\n",
      "BERT-base\n",
      "+FreeLB SAcc- Dtest92:43\u00060:0992.53 92.36\n",
      "RAcc 4:09\u00065:5710.50 0.47\n",
      "+InfoBERT SAcc- Dtest92:68\u00060:2392.90 92.44\n",
      "RAcc 11:98\u000613:1926.40 0.53\n",
      "+RSMI SAcc- Dtest91:53\u00060:5992.20 91.07\n",
      "RAcc 55:69\u00060:8456.40 54.77\n",
      "Table 5: Training stability comparison of RSMI with\n",
      "the baselines on IMDb. The statistics are obtained by\n",
      "training models three times with a different random ini-\n",
      "tialization.\n",
      "decreasing SAcc.\n",
      "4.7 Training stability\n",
      "We investigate the stability of RSMI’s training\n",
      "dynamics. Table 5 summarizes average (Avg),\n",
      "standard deviation (Std), max, and min values of\n",
      "SAcc-Dtestand RAcc obtained from models trained\n",
      "with three different random initializations on IMDb.\n",
      "Note that SAcc-Dtestrepresents SAcc for the whole\n",
      "test set. As shown in the table, RSMI tends to show\n",
      "higher stability compared to the baselines in terms\n",
      "of RAcc despite its stochastic nature. Despite the\n",
      "high and stable SAcc gains from FreeLB and In-\n",
      "foBERT, they tend to show signiﬁcant standard\n",
      "deviations in RAcc and substantial gaps between\n",
      "the max and the min of RAcc.\n",
      "5 Conclusion\n",
      "We have proposed RSMI, a novel two-stage frame-\n",
      "work to tackle the issue of adversarial robustness of\n",
      "large-scale deep NLP systems. RSMI ﬁrst adapts\n",
      "the randomized smoothing (RS) strategy for dis-\n",
      "crete text inputs and leverages a novel gradient-\n",
      "guided masked inference (MI) approach that rein-\n",
      "forces the smoothing effect of RS. We have evalu-\n",
      "ated RSMI by applying it to large-scale pre-trained\n",
      "models on three benchmark datasets and obtain 2\n",
      "to3times improvements against strong attacks in\n",
      "terms of robustness evaluation metrics over state-\n",
      "of-the-art defense methods. We have also studiedthe scalability of RSMI and performed extensive\n",
      "qualitative analyses to examine the effect of RSMI\n",
      "on the latent representations of the original and per-\n",
      "turbed inputs as well as the change in its stability\n",
      "owing to its non-deterministic nature. Our thor-\n",
      "ough experiments and theoretical studies validate\n",
      "the effectiveness of RSMI as a practical approach\n",
      "to train adversarially robust NLP systems.\n",
      "6 Limitations\n",
      "A major component of RSMI has been developed\n",
      "with the concept of randomized smoothing which is\n",
      "known to be certiﬁably robust within a radius of a\n",
      "ball around an input point. Though we have proved\n",
      "the robustness for the perturbed samples within this\n",
      "given ball, there is no theoretical guarantee that a\n",
      "perturbed sample will always lie within the ball.\n",
      "Accordingly, our study is limited to empirical val-\n",
      "idation of the effectiveness of RSMI, although it\n",
      "has theoretical robustness within a L2norm ball as\n",
      "shown in §2. Nevertheless, certiﬁed robustness is a\n",
      "critical research direction for robust and reliable de-\n",
      "ployment of NLP systems to address undiscovered\n",
      "attacks. In our future work, we will explore the the-\n",
      "oretical understanding of the certiﬁed-robustness\n",
      "of NLP systems and textual adversarial examples\n",
      "in-depth.\n",
      "7 Ethics Statement\n",
      "The growing concern over the robustness of deep\n",
      "NLP systems has lead many to dedicate to develop\n",
      "various defense schemes but they have been typi-\n",
      "cally broken by stronger attack algorithms. The pro-\n",
      "posed method demonstrates its effectiveness and\n",
      "potential to serve as a strong defense scheme for\n",
      "text classiﬁcation systems. However, the disclosure\n",
      "of the proposed method may result in attack algo-\n",
      "rithms that are speciﬁc to target RSMI. Nonethe-\n",
      "less, our theoretical study demonstrates that RSMI\n",
      "provides certiﬁable robustness to the NLP systems\n",
      "within a ball with a radius R, which is distinctive\n",
      "compared many other empirical methods, including\n",
      "gradient- and synonym-based works.\n",
      "8 Acknowledgements\n",
      "This work is partly supported by SIMTech-NTU\n",
      "Joint Laboratory on Complex Systems. We would\n",
      "like to thank the anonymous reviewers for their\n",
      "insightful comments. We would also like to thank\n",
      "Min Jeong Song for her valuable input and proof-\n",
      "reading of the paper.\n"
     ]
    }
   ],
   "source": [
    "# Read in the research paper data\n",
    "pdf_file = open('file2.pdf', 'rb')\n",
    "\n",
    "# Create a PDF reader object\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "num_pages = len(pdf_reader.pages)\n",
    "\n",
    "# Loop through all the pages in the PDF document and extract the text\n",
    "text = \"\"\n",
    "for i in range(num_pages):\n",
    "    # Get the page object\n",
    "    page = pdf_reader.pages[i]\n",
    "\n",
    "    # Extract the text from the page\n",
    "    page_text = page.extract_text()\n",
    "\n",
    "    # Append the text to the document text\n",
    "    text += page_text\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()\n",
    "\n",
    "\n",
    "# Define a regular expression to match the word \"References\" and everything that follows it\n",
    "references_pattern = re.compile(r'References(.*)', re.DOTALL)\n",
    "\n",
    "# Use the regular expression to remove the text after \"References\"\n",
    "text = references_pattern.sub('', text)\n",
    "\n",
    "# Define a regular expression to match equations\n",
    "equations_pattern = re.compile(r'.*?=.+')\n",
    "\n",
    "\n",
    "updated_text = re.sub(r\".*Abstract[^:]+:\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "print(updated_text.strip())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T13:24:07.551282400Z",
     "start_time": "2023-05-13T13:24:06.103736Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving in JSON format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a dictionary to store the non-abstract text\n",
    "data = {\n",
    "    \"category\": \"non-abstract\",\n",
    "    \"text\": updated_text.strip()\n",
    "}\n",
    "\n",
    "# Save the non-abstract data to JSON file\n",
    "with open(\"data.json\", \"a\") as json_file:\n",
    "    json.dump(data, json_file)\n",
    "    json_file.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T13:24:07.581613800Z",
     "start_time": "2023-05-13T13:24:07.551282400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
